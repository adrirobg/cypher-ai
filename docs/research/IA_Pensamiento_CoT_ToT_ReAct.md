# **Arquitecturas Cognitivas para Agentes de Desarrollo de Software Aut√≥nomos: Un An√°lisis Comparativo y Gu√≠a de Implementaci√≥n para CoT, ToT y ReAct**

### **Parte I: Marcos de Razonamiento Fundacionales en Modelos de Lenguaje Grandes**

Esta parte establece la base te√≥rica para comprender c√≥mo "piensan" los agentes de IA modernos. Se analizar√° cada uno de los tres marcos de razonamiento principales, examinando sus mecanismos, propiedades emergentes y limitaciones inherentes a partir de la investigaci√≥n fundamental.

#### **1\. Introducci√≥n: La Evoluci√≥n del Razonamiento en los Agentes de IA**

##### **El Cambio de Paradigma: Del Prompting Simple a las Arquitecturas Cognitivas**

El enfoque inicial para interactuar con los modelos de lenguaje grandes (LLM) se basaba en un simple paradigma de entrada-salida, donde una pregunta directa produc√≠a una respuesta directa.<sup>1</sup> Sin embargo, este m√©todo demuestra ser insuficiente para tareas complejas y de m√∫ltiples pasos que requieren una deliberaci√≥n profunda, como las que se encuentran en el desarrollo de software.<sup>2</sup> Para superar estas limitaciones, han surgido marcos de razonamiento estructurado como Chain of Thought (CoT), Tree of Thoughts (ToT) y ReAct (Reasoning and Acting). Estos no son meros "trucos de prompting", sino que deben entenderse como emulaciones de procesos cognitivos humanos que permiten una resoluci√≥n de problemas m√°s robusta, fiable y transparente.<sup>3</sup>

##### **La Emergencia del Razonamiento como Funci√≥n de la Escala**

Un hallazgo cr√≠tico en la investigaci√≥n de los LLM es que las capacidades de razonamiento complejas, particularmente las que aprovecha el CoT, son una propiedad emergente de la escala del modelo.<sup>5</sup> Estas habilidades no se manifiestan de manera significativa en modelos m√°s peque√±os, sino que surgen y se fortalecen a medida que los modelos superan un umbral de aproximadamente 100 mil millones de par√°metros.<sup>2</sup> Este fen√≥meno sugiere que los modelos m√°s grandes, entrenados en conjuntos de datos masivos, aprenden patrones de razonamiento matizados que les permiten seguir secuencias l√≥gicas paso a paso. Este contexto es fundamental: las t√©cnicas discutidas en este informe son m√°s efectivas cuando se aplican a los LLM de √∫ltima generaci√≥n y de gran escala.

##### **El Agente Coder como Dominio de Aplicaci√≥n Principal**

El desarrollo de software representa un dominio de aplicaci√≥n ideal para estos marcos de razonamiento avanzados. Su naturaleza intr√≠nsecamente estructurada, la complejidad l√≥gica de los algoritmos, y la necesidad constante de interactuar con herramientas externas ‚Äîcomo compiladores, suites de pruebas, sistemas de control de versiones y APIs‚Äî lo convierten en un campo de pruebas perfecto. Los "agentes coder" (agentes de IA especializados en desarrollo de c√≥digo como Claude Code o los que ofrece CodeGPT) son el foco central de este informe, ya que su eficacia depende directamente de la sofisticaci√≥n de su arquitectura cognitiva subyacente.<sup>6</sup>

#### **2\. Chain of Thought (CoT): Razonamiento Lineal y Descomposici√≥n de Problemas**

##### **Mecanismo Central**

Chain of Thought (CoT) es una t√©cnica que mejora dr√°sticamente la capacidad de los LLM para abordar problemas complejos al instruirlos para que generen una serie de pasos de razonamiento intermedios y secuenciales que conducen a una respuesta final.<sup>7</sup> Este proceso, que imita la resoluci√≥n de problemas paso a paso de los humanos, permite al modelo descomponer un desaf√≠o abrumador en partes m√°s manejables, asignando as√≠ m√°s recursos computacionales a problemas que requieren una mayor deliberaci√≥n.<sup>2</sup>

##### **Variantes de Implementaci√≥n**

Existen dos variantes principales para implementar el CoT:

- **Few-Shot CoT**: Este es el m√©todo original, que consiste en proporcionar al modelo algunos ejemplos expl√≠citos de tripletes (entrada, cadena de pensamiento, salida) en el prompt.<sup>7</sup> Al ver estos ejemplos, el modelo aprende a replicar el patr√≥n de razonamiento para nuevas consultas. Este enfoque es muy eficaz pero requiere la creaci√≥n manual de ejemplos de alta calidad.<sup>2</sup>
- **Zero-Shot CoT**: Un m√©todo m√°s simple que no requiere ejemplos. En su lugar, se a√±ade una instrucci√≥n directa al final del prompt, como "Pensemos paso a paso" ("Let's think step-by-step").<sup>11</sup> Esto provoca que el modelo genere una cadena de razonamiento por s√≠ mismo. Su eficacia depende en gran medida de las capacidades de seguimiento de instrucciones del modelo, que han mejorado notablemente en los modelos modernos afinados (instruction-tuned).<sup>5</sup>

##### **Fortalezas**

- **Mejora de la Precisi√≥n**: CoT aumenta significativamente el rendimiento en tareas que requieren razonamiento aritm√©tico, de sentido com√∫n y simb√≥lico al evitar que el modelo salte a una conclusi√≥n incorrecta.<sup>7</sup>
- **Interpretabilidad y Depuraci√≥n**: La cadena de razonamiento expl√≠cita ofrece una ventana transparente al "proceso de pensamiento" del modelo. Esto es invaluable para la depuraci√≥n, ya que permite a los usuarios identificar exactamente d√≥nde fall√≥ la l√≥gica y refinar los prompts o el enfoque en consecuencia.<sup>5</sup>

##### **Debilidades**

- **Propagaci√≥n de Errores**: La naturaleza lineal del CoT es su tal√≥n de Aquiles. Sigue un √∫nico camino l√≥gico, por lo que un error cometido en una etapa temprana se propagar√° inevitablemente a trav√©s de la cadena, llevando casi con seguridad a una respuesta final incorrecta.<sup>10</sup>
- **Alucinaci√≥n de Hechos**: Cuando no est√° anclado a informaci√≥n externa, el CoT se basa √∫nicamente en el conocimiento interno y est√°tico del modelo. Si este conocimiento es incorrecto, obsoleto o simplemente inventado (una "alucinaci√≥n"), la cadena de razonamiento, aunque l√≥gicamente coherente, ser√° factualmente err√≥nea.<sup>15</sup>
- **Dependencia de la Escala del Modelo**: Como se mencion√≥ anteriormente, el CoT no ofrece beneficios, e incluso puede ser perjudicial, para modelos m√°s peque√±os. Es una habilidad emergente que solo se manifiesta en LLM de muy gran escala.<sup>2</sup>

#### **3\. Tree of Thoughts (ToT): Exploraci√≥n Estrat√©gica y Deliberaci√≥n**

##### **Mecanismo Central**

Tree of Thoughts (ToT) es una generalizaci√≥n del CoT que supera su limitaci√≥n lineal. En lugar de seguir una √∫nica cadena, ToT estructura el proceso de razonamiento como un √°rbol, permitiendo al modelo explorar m√∫ltiples y divergentes caminos de razonamiento de forma simult√°nea.<sup>1</sup> Este enfoque permite una exploraci√≥n deliberada, la planificaci√≥n con anticipaci√≥n (lookahead) y la capacidad de retroceder (backtracking) cuando un camino resulta ser un callej√≥n sin salida, imitando un proceso de resoluci√≥n de problemas m√°s sofisticado y humano.<sup>18</sup>

##### **Componentes del Marco ToT**

El marco ToT se compone de tres elementos clave que trabajan en conjunto:

1. **Generaci√≥n de Pensamientos**: A partir de un estado del problema, se le solicita al LLM que genere varios "pensamientos" o siguientes pasos potenciales. Cada pensamiento se convierte en una nueva rama en el √°rbol.<sup>21</sup> Estos pueden ser generados de forma independiente (muestreo) o como propuestas secuenciales que contin√∫an un camino existente.<sup>23</sup>
2. **Evaluaci√≥n de Estados**: Este es un componente crucial de la deliberaci√≥n. El propio LLM se utiliza para evaluar la viabilidad o el valor de cada pensamiento generado. Esta evaluaci√≥n puede tomar la forma de una puntuaci√≥n de valor (p. ej., calificar un paso en un problema matem√°tico como "seguro/quiz√°s/imposible") o un mecanismo de votaci√≥n en el que se comparan varios caminos para determinar el m√°s prometedor.<sup>21</sup> Esta capacidad de autoevaluaci√≥n es lo que permite al modelo tomar decisiones informadas sobre qu√© caminos explorar.<sup>19</sup>
3. **Algoritmo de B√∫squeda**: ToT integra algoritmos de b√∫squeda cl√°sicos para navegar por el √°rbol de pensamientos. Los m√°s comunes son la B√∫squeda en Anchura (BFS), que explora todos los nodos de un nivel antes de pasar al siguiente, y la B√∫squeda en Profundidad (DFS), que explora una rama hasta el final antes de retroceder.<sup>24</sup> Estos algoritmos utilizan las evaluaciones de estado para decidir qu√© ramas podar (descartar) y cu√°les expandir, gestionando eficientemente el espacio de b√∫squeda.

##### **Fortalezas**

- **Resoluci√≥n Mejorada de Problemas Complejos**: ToT sobresale en tareas que requieren planificaci√≥n, b√∫squeda o donde existen m√∫ltiples soluciones viables, como la resoluci√≥n de puzles (p. ej., el Juego del 24) o la planificaci√≥n estrat√©gica.<sup>11</sup> Supera con creces a CoT en estos escenarios no lineales.<sup>14</sup>
- **Mitigaci√≥n de Errores**: Al explorar m√∫ltiples caminos, ToT es inherentemente m√°s robusto frente a los errores tempranos. Un error en una rama no condena toda la soluci√≥n, ya que otras ramas pueden seguir siendo viables. Las ramas poco prometedoras se identifican y se podan, evitando la propagaci√≥n de errores que afecta al CoT.<sup>1</sup>

##### **Debilidades**

- **Intensidad Computacional**: La generaci√≥n y evaluaci√≥n de m√∫ltiples ramas consume significativamente m√°s recursos computacionales (tokens) y tiempo que una √∫nica cadena de CoT.<sup>14</sup> Esto lo hace menos eficiente para problemas simples.
- **Complejidad de Implementaci√≥n**: A diferencia del CoT, que puede ser tan simple como a√±adir una frase a un prompt, ToT es un marco complejo. Requiere un dise√±o cuidadoso de los prompts de generaci√≥n y evaluaci√≥n, as√≠ como la integraci√≥n de un algoritmo de b√∫squeda, lo que supone un esfuerzo de ingenier√≠a considerable.<sup>22</sup>

#### **4\. Reasoning and Acting (ReAct): Sinergia entre Pensamiento y Herramientas Externas**

##### **Mecanismo Central**

El marco ReAct crea un potente bucle sin√©rgico entre el razonamiento interno y la acci√≥n externa. En lugar de depender √∫nicamente de su conocimiento est√°tico, el LLM genera secuencias intercaladas de **Pensamiento** (razonamiento verbalizado interno), **Acci√≥n** (una llamada a una herramienta externa) y **Observaci√≥n** (el resultado devuelto por la herramienta).<sup>15</sup> Este ciclo permite al modelo interactuar con su entorno para recopilar informaci√≥n actualizada y fundamentar su razonamiento.<sup>28</sup>

##### **El Bucle ReAct**

El proceso se desarrolla de la siguiente manera:

1. **Pensamiento (Thought)**: El LLM analiza la tarea y su estado actual, verbalizando un plan o un paso de razonamiento. Por ejemplo: "Necesito averiguar la versi√≥n actual de la biblioteca 'requests' y si tiene alguna vulnerabilidad de seguridad conocida".
2. **Acci√≥n (Action)**: Basado en el pensamiento, el LLM genera una acci√≥n espec√≠fica y ejecutable para interactuar con una herramienta externa. Por ejemplo: search("requests library PyPI version") o security_scan("requests").
3. **Observaci√≥n (Observation)**: El sistema ejecuta la acci√≥n (p. ej., realiza la b√∫squeda web o ejecuta el esc√°ner) y devuelve el resultado al LLM. Por ejemplo: "Resultado de la b√∫squeda: 'requests 2.31.0'. Resultado del esc√°ner: 'No se encontraron vulnerabilidades cr√≠ticas'".
4. El bucle se repite, con la nueva observaci√≥n informando el siguiente pensamiento, permitiendo al agente refinar su plan y acercarse a la soluci√≥n.

##### **Fortalezas**

- **Fundamentaci√≥n y Veracidad**: Al interactuar con herramientas externas (APIs, bases de datos, b√∫squeda web, terminales de comandos), ReAct ancla el razonamiento del LLM en informaci√≥n del mundo real, actualizada y verificable. Esto reduce dr√°sticamente las alucinaciones y supera la limitaci√≥n fundamental del conocimiento est√°tico del modelo.<sup>13</sup>
- **Adaptabilidad Din√°mica**: El marco es inherentemente din√°mico. El agente puede ajustar su plan sobre la marcha bas√°ndose en las observaciones que recibe, manejar excepciones (p. ej., una API que devuelve un error) y recuperarse de acciones fallidas, mostrando una robustez similar a la humana.<sup>26</sup>
- **Interpretabilidad Mejorada**: El rastro expl√≠cito de pensamiento-acci√≥n-observaci√≥n proporciona un registro claro y legible por humanos del comportamiento del agente. Esto facilita enormemente la depuraci√≥n, la auditor√≠a y la generaci√≥n de confianza en las decisiones del sistema.<sup>29</sup>

##### **Debilidades**

- **Dependencia de la Calidad de las Herramientas**: El rendimiento de un agente ReAct est√° directamente ligado a la calidad, fiabilidad y dise√±o de las herramientas disponibles. Una herramienta que devuelve informaci√≥n no informativa, irrelevante o err√≥nea puede desviar por completo el proceso de razonamiento del agente.<sup>16</sup>
- **Restricciones Estructurales**: El formato estricto Pensamiento-Acci√≥n-Observaci√≥n puede ser menos flexible o eficiente para tareas que son puramente de razonamiento interno, donde un CoT m√°s directo podr√≠a ser suficiente y consumir menos recursos.<sup>16</sup>

### **Parte II: Aplicaci√≥n Estrat√©gica para Agentes de Desarrollo de Software**

Esta parte pasa de la teor√≠a a la aplicaci√≥n, analizando c√≥mo cada marco de razonamiento puede ser desplegado estrat√©gicamente por un agente coder para abordar los desaf√≠os multifac√©ticos del ciclo de vida del desarrollo de software.

#### **5\. An√°lisis Comparativo: Adaptando Arquitecturas Cognitivas a Tareas de Software**

Ning√∫n marco de razonamiento es √≥ptimo para todas las tareas del desarrollo de software. Un agente programador verdaderamente avanzado no ser√° un "agente CoT" o un "agente ReAct", sino un sistema sofisticado capaz de cambiar din√°micamente su modo cognitivo ‚ÄîCoT, ToT o ReAct‚Äî en funci√≥n de la tarea espec√≠fica que tenga entre manos. Este concepto de "cambio de modo cognitivo" es an√°logo a c√≥mo un desarrollador humano opera: a veces se enfoca en una codificaci√≥n lineal y profunda, otras veces realiza una lluvia de ideas arquitect√≥nicas con m√∫ltiples ramas, y otras veces entra en un bucle interactivo de depuraci√≥n.

El ciclo de vida del desarrollo de software se puede desglosar en fases distintas, cada una de las cuales se alinea mejor con una arquitectura cognitiva espec√≠fica:

1. **Planificaci√≥n de Alto Nivel**: Tareas como la elecci√≥n de una arquitectura de software, la selecci√≥n de un stack tecnol√≥gico o el dise√±o de la estructura de una base de datos implican explorar y comparar m√∫ltiples alternativas mutuamente excluyentes. Este escenario es un mal ajuste para el CoT lineal, pero es precisamente donde brilla el ToT, con su capacidad para explorar y evaluar ramas de decisi√≥n paralelas.<sup>3</sup>
2. **Dise√±o e Implementaci√≥n de Componentes**: Una vez que se ha tomado una decisi√≥n de alto nivel, la implementaci√≥n de una funci√≥n o m√≥dulo bien definido se convierte en un proceso m√°s lineal. El desarrollador sigue una secuencia l√≥gica de pasos: definir la interfaz, manejar los casos de borde, escribir la l√≥gica principal, etc. Este proceso se asigna perfectamente a la descomposici√≥n paso a paso del CoT.<sup>7</sup>
3. **Desarrollo Iterativo y Depuraci√≥n**: La escritura de c√≥digo en el mundo real rara vez es un proceso de un solo paso. Es un bucle iterativo de escribir c√≥digo, ejecutar pruebas, leer archivos, inspeccionar registros y corregir errores. Este ciclo de acci√≥n y observaci√≥n es la esencia del marco ReAct, lo que lo convierte en el motor de ejecuci√≥n ideal para el trabajo pr√°ctico de codificaci√≥n.<sup>26</sup>

Por lo tanto, una arquitectura de agente de √∫ltima generaci√≥n debe ser un sistema h√≠brido. Deber√≠a emplear ToT para las decisiones estrat√©gicas de alto nivel, cambiar a CoT para planificar la implementaci√≥n de componentes espec√≠ficos y, finalmente, utilizar ReAct como el n√∫cleo de ejecuci√≥n para escribir, probar y depurar el c√≥digo de manera interactiva.

La siguiente tabla sirve como una herramienta de decisi√≥n de referencia r√°pida para los ingenieros que dise√±an agentes programadores, destilando las compensaciones en un formato estructurado.

**Tabla 1: Matriz Comparativa de CoT, ToT y ReAct para Tareas de Desarrollo de Software**

| Framework | Mecanismo Central | Tarea Principal de Software | Tareas Secundarias de Software | Fortalezas en el Contexto de Codificaci√≥n | Debilidades en el Contexto de Codificaci√≥n | Complejidad de Implementaci√≥n |
| --- | --- | --- | --- | --- | --- | --- |
| **Chain of Thought (CoT)** | Descomposici√≥n lineal paso a paso. | Planificaci√≥n de la implementaci√≥n de funciones; Generaci√≥n de explicaciones de c√≥digo. | Creaci√≥n de documentaci√≥n; Refactorizaci√≥n simple. | Proporciona un plan claro y estructurado para la codificaci√≥n. Mejora la interpretabilidad del proceso de generaci√≥n de c√≥digo.<sup>5</sup> | La propagaci√≥n de errores puede llevar a algoritmos defectuosos. Propenso a alucinar sobre APIs o sintaxis si no se verifica.<sup>14</sup> | Baja |
| --- | --- | --- | --- | --- | --- | --- |
| **Tree of Thoughts (ToT)** | Exploraci√≥n y evaluaci√≥n de m√∫ltiples caminos de razonamiento en paralelo. | Planificaci√≥n arquitect√≥nica; Dise√±o de algoritmos complejos; Selecci√≥n de tecnolog√≠a. | Refactorizaci√≥n a gran escala; Optimizaci√≥n de rendimiento. | Permite comparar arquitecturas (p. ej., monolito vs. microservicios) o algoritmos (p. ej., quicksort vs. mergesort) antes de la implementaci√≥n.<sup>1</sup> Mitiga el riesgo de elegir un camino sub√≥ptimo.<sup>10</sup> | Computacionalmente costoso para tareas simples de codificaci√≥n. La sobrecarga de la b√∫squeda puede ralentizar el desarrollo r√°pido.<sup>14</sup> | Alta |
| --- | --- | --- | --- | --- | --- | --- |
| **ReAct (Reasoning + Acting)** | Bucle iterativo de Pensamiento-Acci√≥n-Observaci√≥n con herramientas externas. | Desarrollo iterativo; Depuraci√≥n; Pruebas; Integraci√≥n continua. | B√∫squeda de documentaci√≥n; An√°lisis de dependencias; Escaneo de seguridad. | Fundamenta la generaci√≥n de c√≥digo en el estado real del repositorio (mediante herramientas de E/S de archivos). Permite un bucle robusto de prueba-correcci√≥n-reprueba. Reduce la alucinaci√≥n sobre versiones de bibliotecas al permitir verificaciones en tiempo real.<sup>15</sup> | Ineficiente para el dise√±o de algoritmos puros donde no se necesita interacci√≥n con herramientas. La latencia del bucle puede ser excesiva para la generaci√≥n de c√≥digo simple de un solo paso.<sup>16</sup> | Media |
| --- | --- | --- | --- | --- | --- | --- |

#### **6\. CoT en la Pr√°ctica: De la Planificaci√≥n Algor√≠tmica a la Explicaci√≥n Post-Hoc**

En el contexto de la codificaci√≥n, CoT puede utilizarse de dos maneras estrat√©gicas. La primera es la **planificaci√≥n previa a la computaci√≥n**: antes de escribir una funci√≥n compleja, el agente puede usar CoT para generar un plan detallado en lenguaje natural o pseudoc√≥digo.<sup>5</sup> Este plan sirve como un prompt altamente contextualizado para el paso final de generaci√≥n de c√≥digo, guiando al modelo hacia una implementaci√≥n m√°s l√≥gica y estructurada.

Sin embargo, una aplicaci√≥n m√°s profunda y contraintuitiva surge en el contexto del afinamiento (fine-tuning) de modelos de c√≥digo. Una investigaci√≥n revel√≥ que para esta tarea, invertir el orden tradicional a prompt -> c√≥digo -> CoT produjo una mejora significativa del rendimiento (hasta un 9.86%) en comparaci√≥n con el enfoque est√°ndar de prompt -> CoT -> c√≥digo.<sup>33</sup>

Este hallazgo sugiere una din√°mica fundamental sobre c√≥mo los LLM manejan dominios especializados como el c√≥digo:

1. El paradigma est√°ndar CoT -> c√≥digo asume que el razonamiento en lenguaje natural es el precursor causal del buen c√≥digo.
2. Sin embargo, la "habilidad" de un LLM para generar c√≥digo idiom√°tico y sint√°cticamente correcto puede ser una capacidad de coincidencia de patrones m√°s intuitiva y distinta de su "habilidad" para articular pasos l√≥gicos en prosa.
3. Forzar al modelo a razonar primero podr√≠a restringir o interferir con su potente capacidad de generaci√≥n de c√≥digo. Podr√≠a producir un c√≥digo forzado y literal que sigue la prosa, en lugar de un c√≥digo idiom√°tico y eficiente.
4. El paradigma c√≥digo -> CoT desacopla estas dos habilidades. Primero, el modelo genera el c√≥digo utilizando toda su capacidad de coincidencia de patrones. Luego, realiza una tarea separada y posiblemente m√°s sencilla: explicar el c√≥digo que acaba de escribir.
5. La implicaci√≥n m√°s amplia es que, para dominios altamente especializados, el "pensamiento" puede ser una racionalizaci√≥n post-hoc en lugar de un razonamiento a priori. Esto tiene profundas consecuencias sobre c√≥mo se deben estructurar los datos de entrenamiento para agentes especializados. El CoT no solo beneficia al agente, sino que se convierte en un artefacto valioso para la mantenibilidad y la comprensi√≥n por parte de los desarrolladores humanos.

Como gu√≠a accionable, se recomienda que al afinar un agente programador, los datos de entrenamiento se estructuren como tripletas de (pregunta, c√≥digo_final, explicaci√≥n_CoT). Esta CoT generada puede luego ser integrada como comentarios de c√≥digo, mejorando directamente la calidad y mantenibilidad del software producido.<sup>33</sup>

#### **7\. ToT en la Pr√°ctica: Planificaci√≥n Arquitect√≥nica y Dise√±o Algor√≠tmico**

ToT es el marco ideal para las fases iniciales y m√°s estrat√©gicas del desarrollo de software, donde la exploraci√≥n y evaluaci√≥n de alternativas de alto nivel es crucial.<sup>3</sup>

Un ejemplo claro es la **selecci√≥n de una arquitectura o tecnolog√≠a**. Consideremos el siguiente flujo de trabajo para un agente encargado de "seleccionar una base de datos para una nueva aplicaci√≥n de red social":

1. **Nodo Ra√≠z (Problema)**: "Seleccionar una base de datos para una nueva aplicaci√≥n de red social con requisitos de alta escalabilidad y consultas de conexi√≥n complejas."
2. **Generaci√≥n de Pensamientos (Ramas)**: El agente genera varias alternativas de alto nivel.
    - "Camino A: Usar una base de datos relacional como PostgreSQL, aprovechando su robustez y transaccionalidad."
    - "Camino B: Usar un almac√©n de documentos NoSQL como MongoDB, para una mayor flexibilidad de esquema."
    - "Camino C: Usar una base de datos de grafos como Neo4j, optimizada para consultas de relaciones sociales."
3. **Evaluaci√≥n de Estados**: El agente eval√∫a cada camino contra los requisitos clave. Utilizando el propio LLM, asigna puntuaciones o valoraciones a cada rama. Por ejemplo, podr√≠a concluir que PostgreSQL (Camino A) es excelente para la integridad de los datos pero podr√≠a enfrentar desaf√≠os de escalabilidad horizontal, mientras que Neo4j (Camino C) es perfecto para el grafo social pero menos ideal para almacenar contenido de usuario como publicaciones o mensajes.
4. **Poda y Exploraci√≥n**: Bas√°ndose en la evaluaci√≥n, el agente podr√≠a podar caminos menos prometedores o expandir los m√°s viables. Podr√≠a concluir que una arquitectura h√≠brida (usando PostgreSQL para los datos de usuario y Neo4j para las conexiones) es la soluci√≥n √≥ptima, generando as√≠ una decisi√≥n arquitect√≥nica matizada y bien razonada que ser√≠a dif√≠cil de alcanzar con un enfoque lineal.

De manera similar, para el **dise√±o de algoritmos complejos**, ToT permite al agente explorar diferentes estrategias de implementaci√≥n (p. ej., un enfoque recursivo vs. uno iterativo), comparar su complejidad te√≥rica en tiempo y espacio, y seleccionar el enfoque m√°s √≥ptimo antes de escribir una sola l√≠nea de c√≥digo.<sup>34</sup>

#### **8\. ReAct en la Pr√°ctica: El N√∫cleo del Agente Coder Interactivo**

El ciclo de desarrollo diario de un programador ‚Äîescribir, compilar, probar, depurar‚Äî se puede modelar directamente como un bucle ReAct.<sup>26</sup> Aqu√≠, el agente no solo genera c√≥digo, sino que interact√∫a activamente con el entorno de desarrollo.

El poder de un agente ReAct reside en su **conjunto de herramientas**. Un agente programador eficaz debe estar equipado con herramientas que le permitan percibir y manipular su entorno de desarrollo. Un conjunto de herramientas esencial incluir√≠a:

- **Herramientas del Sistema de Archivos**: read_file(path), write_file(path, content), list_directory(path). Para leer el c√≥digo existente, escribir nuevo c√≥digo y navegar por la estructura del proyecto.
- **Herramientas de Ejecuci√≥n de C√≥digo**: execute_python_script(path), execute_shell_command(command). Para ejecutar el c√≥digo, instalar dependencias o ejecutar scripts de compilaci√≥n.
- **Herramientas de Pruebas**: run_unit_tests(path), run_integration_tests(). Para validar la funcionalidad del c√≥digo y detectar regresiones.
- **Herramientas de Validaci√≥n y An√°lisis**: lint_code(path), run_static_analysis(), scan_for_security_vulnerabilities(). Para garantizar la calidad, el estilo y la seguridad del c√≥digo, abordando directamente los desaf√≠os de fiabilidad del c√≥digo generado por LLM.<sup>37</sup>
- **Herramientas de Recuperaci√≥n de Informaci√≥n**: web_search(query) para buscar documentaci√≥n de API o soluciones a errores, y vector_search_codebase(query) para encontrar fragmentos de c√≥digo relevantes dentro del propio repositorio.

A continuaci√≥n se muestra un **ejemplo de traza de una sesi√≥n de depuraci√≥n con ReAct**, donde el agente debe corregir un error en un script de Python:

- **Entrada Inicial**: "El script calculator.py falla en la prueba test_divide_by_zero con un error ZeroDivisionError."
- **Traza del Agente**:
  - **Pensamiento 1**: El error es un ZeroDivisionError en test_divide_by_zero. Necesito examinar el c√≥digo de la funci√≥n de divisi√≥n en calculator.py y el c√≥digo de la prueba en tests/test_calculator.py para entender la causa.
  - **Acci√≥n 1**: read_file('calculator.py')
  - **Observaci√≥n 1**: (Contenido de calculator.py, mostrando def divide(a, b): return a / b)
  - **Pensamiento 2**: La funci√≥n divide no maneja el caso en que b es cero. Esta es la causa probable del error. Necesito modificar la funci√≥n para que levante una excepci√≥n ValueError si el divisor es cero, como es la pr√°ctica com√∫n en Python.
  - **Acci√≥n 2**: write_file('calculator.py', 'def divide(a, b):\\n if b == 0:\\n raise ValueError("Cannot divide by zero")\\n return a / b')
  - **Observaci√≥n 2**: "Archivo calculator.py actualizado con √©xito."
  - **Pensamiento 3**: He modificado el c√≥digo. Ahora necesito ejecutar las pruebas nuevamente para verificar que la correcci√≥n funciona y no he introducido nuevas regresiones.
  - **Acci√≥n 3**: run_unit_tests('tests/test_calculator.py')
  - **Observaci√≥n 3**: "Todas las pruebas pasaron con √©xito."
  - **Pensamiento 4**: El error ha sido corregido y las pruebas lo confirman. La tarea est√° completa.
  - **Acci√≥n 4**: finish("El bug ha sido corregido en calculator.py y todas las pruebas pasan.")

Este ejemplo concreto ilustra c√≥mo el bucle Pensamiento-Acci√≥n-Observaci√≥n permite al agente diagnosticar, actuar y verificar de manera sistem√°tica, reflejando el flujo de trabajo de un desarrollador humano.<sup>40</sup>

### **Parte III: Gu√≠a de Implementaci√≥n y Planos Accionables**

Esta parte final proporciona la gu√≠a pr√°ctica, traduciendo las discusiones te√≥ricas y estrat√©gicas en orientaci√≥n accionable para construir y desplegar agentes programadores eficaces.

#### **9\. Una Gu√≠a Pr√°ctica para Implementar Agentes Coder**

##### **Prompting Estructurado para Agentes Coder**

Un prompting eficaz es crucial para guiar el comportamiento del agente. El uso de un formato estructurado, como las etiquetas XML recomendadas por Anthropic, hace que la salida del modelo sea m√°s predecible, m√°s f√°cil de analizar y ayuda al propio modelo a separar su razonamiento de su entregable final.<sup>42</sup> Se deben utilizar etiquetas como

&lt;thinking&gt;, &lt;plan&gt;, &lt;code&gt; y &lt;explanation&gt; para delimitar las diferentes partes de la salida del agente.

La siguiente tabla proporciona plantillas de prompts listas para usar que los desarrolladores pueden adaptar, ahorrando un tiempo y esfuerzo significativos en la ingenier√≠a de prompts.

**Tabla 2: Plantillas de Prompts para Agentes Coder**

| Tarea | Marco de Razonamiento | Plantilla de Prompt |
| --- | --- | --- |
| **Generaci√≥n de Funci√≥n** | CoT | Usted es un desarrollador experto en Python. Su tarea es escribir una funci√≥n que cumpla con los siguientes requisitos: &lt;requisitos&gt;{{REQUISITOS}}&lt;/requisitos&gt;. Antes de escribir el c√≥digo, piense paso a paso dentro de etiquetas &lt;plan&gt; para delinear su enfoque. Luego, escriba el c√≥digo final dentro de etiquetas &lt;code&gt;. Finalmente, proporcione una breve explicaci√≥n en etiquetas &lt;explanation&gt;. |
| --- | --- | --- |
| **Planificaci√≥n Arquitect√≥nica** | ToT | Imagine a tres arquitectos de software expertos discutiendo la mejor arquitectura para el siguiente problema: {{PROBLEMA}}. Cada experto debe proponer un enfoque inicial (p. ej., monol√≠tico, microservicios, sin servidor). Luego, cada uno debe evaluar los pros y los contras de cada enfoque en el contexto de los requisitos del problema. Deben debatir y refinar sus ideas hasta llegar a una recomendaci√≥n consensuada o a una comparaci√≥n clara de las compensaciones. Estructure la discusi√≥n como un √°rbol de pensamientos, explorando cada rama. |
| --- | --- | --- |
| **Depuraci√≥n de C√≥digo** | ReAct | Usted es un desarrollador experto en Python. Una prueba unitaria est√° fallando. Su objetivo es corregir el c√≥digo para que la prueba pase. Tiene acceso a las siguientes herramientas:. Utilice el siguiente formato:\\nPensamiento:\\nAcci√≥n: \[La herramienta a usar, p. ej., read_file\]\\nEntrada de Acci√≥n: \[La entrada para la herramienta, p. ej., 'tests/test_logic.py'\]\\nObservaci√≥n:\\n... (repita Pensamiento/Acci√≥n/Observaci√≥n N veces)...\\nPensamiento: He corregido el error y las pruebas ahora deber√≠an pasar.\\nAcci√≥n: finish\\n\\nContexto inicial:\\n&lt;error_log&gt;{{MENSAJE_DE_ERROR}}&lt;/error_log&gt;\\n&lt;test_code&gt;{{CONTENIDO_DEL_CODIGO_DE_PRUEBA}}&lt;/test_code&gt; |
| --- | --- | --- |

##### **Implementaci√≥n con Frameworks de Agentes (LangChain y AutoGen)**

- **LangChain**: Es un framework popular para construir aplicaciones con LLM. Para implementar un agente ReAct, se puede utilizar la funci√≥n create_react_agent. Es crucial definir herramientas personalizadas que el agente pueda usar. Por ejemplo, una herramienta run_pytest se puede crear a partir de una funci√≥n de Python que ejecute los tests y devuelva la salida.<sup>43</sup> LangChain proporciona decoradores y clases base para facilitar la creaci√≥n de estas herramientas personalizadas, permitiendo al agente interactuar con cualquier sistema externo.<sup>44</sup>
- **AutoGen**: Este framework de Microsoft se especializa en la creaci√≥n de sistemas multi-agente conversacionales. Se puede utilizar AutoGen Studio, una interfaz de bajo c√≥digo, para configurar un flujo de trabajo donde m√∫ltiples agentes colaboran.<sup>46</sup> Por ejemplo, se podr√≠a crear un "Agente Programador" responsable de escribir el c√≥digo, y un "Agente de QA" responsable de ejecutar las pruebas y reportar los errores. El Agente Programador recibir√≠a los informes de errores del Agente de QA y entrar√≠a en un bucle de correcci√≥n, emulando un equipo de desarrollo de software.

#### **10\. El Flujo de Trabajo Centrado en la Validaci√≥n: Mitigando los Riesgos del C√≥digo LLM**

La barrera m√°s significativa para la adopci√≥n generalizada del c√≥digo generado por LLM es su falta de fiabilidad. El c√≥digo puede ser sint√°cticamente correcto pero contener errores l√≥gicos sutiles, problemas de rendimiento, ineficiencias o, lo que es peor, vulnerabilidades de seguridad cr√≠ticas.<sup>37</sup> Un proceso de revisi√≥n manual por parte de humanos es lento, costoso y a menudo insuficiente para detectar todos los problemas.<sup>49</sup>

Aqu√≠ es donde el marco ReAct puede ser transformador. El problema no es solo generar c√≥digo, sino generar c√≥digo _confiable_. Los desarrolladores humanos generan confianza a trav√©s de un riguroso proceso de validaci√≥n: pruebas, linting, an√°lisis est√°tico y escaneo de seguridad. El marco ReAct est√° perfectamente adaptado para _automatizar_ este mismo proceso de validaci√≥n. Las "Acciones" del agente no deben limitarse a write_file, sino que deben incluir run_linter, run_security_scan y run_tests.

Esto redefine el objetivo del agente: su tarea no est√° completa cuando el c√≥digo est√° escrito, sino cuando el c√≥digo pasa un conjunto predefinido de puertas de calidad. Este enfoque transforma al agente de un simple "generador de c√≥digo" a un "ingeniero de aseguramiento de calidad automatizado", una propuesta de valor mucho m√°s alta que aborda directamente el principal obst√°culo para la adopci√≥n de la IA en el desarrollo de software.

Un **plano para un agente ReAct centrado en la validaci√≥n** incluir√≠a los siguientes pasos:

1. **Definir las Puertas de Calidad**: El agente recibe una "definici√≥n de completado" en su prompt de sistema. Por ejemplo: "El c√≥digo debe estar formateado seg√∫n el est√°ndar PEP 8, pasar todas las reglas del linter, no tener vulnerabilidades cr√≠ticas o altas seg√∫n el esc√°ner de seguridad, y pasar el 100% de las pruebas unitarias."
2. **Bucle de Refinamiento Iterativo**: El agente escribe una primera versi√≥n del c√≥digo.
3. **Ejecuci√≥n de la Validaci√≥n**: El agente ejecuta sistem√°ticamente el c√≥digo a trav√©s de las herramientas de validaci√≥n (linter, esc√°ner, suite de pruebas).
4. **Autocorrecci√≥n**: El agente utiliza la salida (Observaciones) de las herramientas de validaci√≥n para informar su siguiente Pensamiento y Acci√≥n, que consiste en corregir el c√≥digo. Por ejemplo, si el linter reporta una l√≠nea demasiado larga, el agente la reescribir√°. Si una prueba falla, el agente analizar√° el error y modificar√° la l√≥gica.
5. Este bucle contin√∫a hasta que todas las puertas de calidad se superan con √©xito.

#### **11\. Gesti√≥n del Estado para Tareas de Desarrollo Complejas**

El desarrollo de software en el mundo real no es una tarea corta y sin estado. Implica trabajar en m√∫ltiples archivos, recordar decisiones de dise√±o anteriores y mantener un estado coherente durante largos per√≠odos. Las ventanas de contexto de los LLM, aunque cada vez m√°s grandes, siguen siendo una limitaci√≥n fundamental para estas tareas de larga duraci√≥n.<sup>48</sup>

Para abordar este desaf√≠o, se pueden utilizar arquitecturas basadas en grafos como **LangGraph**.<sup>51</sup> LangGraph, una extensi√≥n de LangChain, permite modelar los flujos de trabajo de los agentes como grafos de estado.

- **Gesti√≥n del Estado**: El estado del grafo es un objeto que persiste a lo largo de la ejecuci√≥n del agente. Puede contener informaci√≥n crucial como la lista de archivos modificados, los resultados de las √∫ltimas pruebas, el plan de alto nivel y el historial de conversaci√≥n. Esto proporciona al agente una memoria a largo plazo que va m√°s all√° de la ventana de contexto del LLM.<sup>53</sup>
- **Aristas Condicionales**: LangGraph permite crear flujos de trabajo m√°s complejos que un simple bucle ReAct. Se pueden definir aristas condicionales que dirigen el flujo en funci√≥n del estado. Por ejemplo, despu√©s de una acci√≥n execute_tests, una arista condicional puede enrutar al agente a un nodo de "depuraci√≥n" si las pruebas fallan, o a un nodo de "confirmar_c√≥digo" si pasan. Esto permite un comportamiento de agente mucho m√°s sofisticado, robusto y similar al humano.

#### **12\. Conclusi√≥n y Direcciones Futuras**

El avance de los agentes de IA en el dominio del desarrollo de software depende de la adopci√≥n de arquitecturas cognitivas sofisticadas. Este informe ha analizado tres marcos fundamentales ‚ÄîCoT, ToT y ReAct‚Äî y ha extra√≠do varias conclusiones clave para su aplicaci√≥n pr√°ctica:

1. **La Necesidad de un Enfoque H√≠brido**: El agente programador m√°s eficaz no se adherir√° r√≠gidamente a un √∫nico modo de razonamiento. En su lugar, ser√° un sistema h√≠brido capaz de realizar un "cambio de modo cognitivo", utilizando ToT para la planificaci√≥n estrat√©gica, CoT para la descomposici√≥n de tareas y ReAct como el motor de ejecuci√≥n interactivo.
2. **El Paradigma c√≥digo -> CoT para el Afinamiento**: La investigaci√≥n sugiere que, para afinar modelos de c√≥digo, es m√°s eficaz hacer que el modelo genere primero el c√≥digo y luego la explicaci√≥n (CoT). Esto desacopla la generaci√≥n de c√≥digo basada en patrones de la racionalizaci√≥n en lenguaje natural y produce artefactos de explicaci√≥n valiosos para los desarrolladores humanos.
3. **La Centralidad del Bucle de Validaci√≥n ReAct**: La confianza es el principal obst√°culo para la adopci√≥n del c√≥digo generado por IA. Un flujo de trabajo ReAct centrado en la validaci√≥n, donde el agente es responsable no solo de escribir c√≥digo sino de asegurar que pasa rigurosas puertas de calidad (linting, pruebas, seguridad), es la estrategia m√°s prometedora para construir agentes programadores fiables y listos para la producci√≥n.

El futuro de estos marcos parece dirigirse hacia una mayor integraci√≥n y sofisticaci√≥n. Podemos anticipar algoritmos de b√∫squeda y planificaci√≥n m√°s avanzados para ToT, la estandarizaci√≥n de conjuntos de herramientas para agentes ReAct en diferentes lenguajes y dominios, y la integraci√≥n cada vez m√°s profunda de estas arquitecturas cognitivas directamente en los Entornos de Desarrollo Integrado (IDE) y las plataformas de desarrollo de software de extremo a extremo, transformando fundamentalmente la forma en que se crea el software.<sup>6</sup>

#### Obras citadas

1. Beginner's Guide To Tree Of Thoughts Prompting (With Examples) | Zero To Mastery, fecha de acceso: julio 6, 2025, <https://zerotomastery.io/blog/tree-of-thought-prompting/>
2. Comprehensive Guide to Chain-of-Thought Prompting - Mercity AI, fecha de acceso: julio 6, 2025, <https://www.mercity.ai/blog-post/guide-to-chain-of-thought-prompting>
3. Comparing Reasoning Frameworks: ReAct, Chain-of-Thought, and Tree-of-Thoughts | by allglenn | Stackademic, fecha de acceso: julio 6, 2025, <https://blog.stackademic.com/comparing-reasoning-frameworks-react-chain-of-thought-and-tree-of-thoughts-b4eb9cdde54f>
4. Why does CoT and ToT enhance the performance of LLMs : r/LocalLLM - Reddit, fecha de acceso: julio 6, 2025, <https://www.reddit.com/r/LocalLLM/comments/1ikn2i7/why_does_cot_and_tot_enhance_the_performance_of/>
5. What is chain of thought (CoT) prompting? - IBM, fecha de acceso: julio 6, 2025, <https://www.ibm.com/think/topics/chain-of-thoughts>
6. CodeGPT: AI Agents for Software Development, fecha de acceso: julio 6, 2025, <https://codegpt.co/>
7. Chain-of-Thought Prompting Elicits Reasoning in Large ... - arXiv, fecha de acceso: julio 6, 2025, <https://arxiv.org/pdf/2201.11903>
8. Chain-of-Thought Prompting Elicits Reasoning in Large Language Models - arXiv, fecha de acceso: julio 6, 2025, <https://arxiv.org/abs/2201.11903>
9. Chain of Thought (CoT), Tree of Thought (ToT), and ReAct (Reasoning & Acting) | by Hema Sri Nakirikanti | Medium, fecha de acceso: julio 6, 2025, <https://medium.com/@hemasri.nakirikanti16/chain-of-thought-cot-tree-of-thought-tot-and-react-reasoning-acting-aeab1b94f1d9>
10. Comprehensive Guide to Prompt Engineering Techniques and Applications - Deepchecks, fecha de acceso: julio 6, 2025, <https://www.deepchecks.com/comprehensive-guide-to-prompt-engineering-techniques-and-applications/>
11. Advanced Prompt Engineering Techniques - Mercity AI, fecha de acceso: julio 6, 2025, <https://www.mercity.ai/blog-post/advanced-prompt-engineering-techniques>
12. \[2304.03262\] When do you need Chain-of-Thought Prompting for ChatGPT? - arXiv, fecha de acceso: julio 6, 2025, <https://arxiv.org/abs/2304.03262>
13. 5 Advanced Prompting Techniques to Improve Your LLM App's Responses - athina.ai, fecha de acceso: julio 6, 2025, <https://blog.athina.ai/5-advanced-prompting-techniques-to-improve-your-llm-app-s-responses>
14. Comparing Chain-of-Thought (CoT) and Tree-of-Thought (ToT) Reasoning Models in AI Agents - Monster API, fecha de acceso: julio 6, 2025, <https://blog.monsterapi.ai/chain-of-thought-cot-and-tree-of-thought-tot-reasoning-models-in-ai-agents/>
15. ReAct: Synergizing Reasoning and Acting in Language Models - Google Research, fecha de acceso: julio 6, 2025, <https://research.google/blog/react-synergizing-reasoning-and-acting-in-language-models/>
16. ReAct - Prompt Engineering Guide, fecha de acceso: julio 6, 2025, <https://www.promptingguide.ai/techniques/react>
17. ToTRL: Unlock LLM Tree-of-Thoughts Reasoning Potential through Puzzles Solving - arXiv, fecha de acceso: julio 6, 2025, <https://arxiv.org/html/2505.12717v1>
18. What is Tree Of Thoughts Prompting? - IBM, fecha de acceso: julio 6, 2025, <https://www.ibm.com/think/topics/tree-of-thoughts>
19. Tree of Thoughts: Deliberate Problem Solving with Large Language Models - arXiv, fecha de acceso: julio 6, 2025, <https://arxiv.org/html/2305.10601v2>
20. Tree of Thoughts: Deliberate Problem Solving with Large Language Models - OpenReview, fecha de acceso: julio 6, 2025, <https://openreview.net/forum?id=5Xc1ecxO1h>
21. Improving LLM Reasoning with Multi-Agent Tree-of-Thought Validator Agent - arXiv, fecha de acceso: julio 6, 2025, <https://arxiv.org/html/2409.11527v2>
22. Tree of Thought (ToT) prompting - GeeksforGeeks, fecha de acceso: julio 6, 2025, <https://www.geeksforgeeks.org/artificial-intelligence/tree-of-thought-tot-prompting/>
23. princeton-nlp/tree-of-thought-llm: \[NeurIPS 2023\] Tree of Thoughts: Deliberate Problem Solving with Large Language Models - GitHub, fecha de acceso: julio 6, 2025, <https://github.com/princeton-nlp/tree-of-thought-llm>
24. Tree of Thoughts (ToT) | Prompt Engineering Guide, fecha de acceso: julio 6, 2025, <https://www.promptingguide.ai/techniques/tot>
25. Prompt Engineering Techniques. Chain of Thought (CoT)‚Ä¶ | by Gul Gultekin Erdem | Medium, fecha de acceso: julio 6, 2025, <https://medium.com/@GULGULTEKIN/prompt-engineering-techniques-37a473ed25a6>
26. ReAct: Synergizing Reasoning and Acting in Language Models - arXiv, fecha de acceso: julio 6, 2025, <https://arxiv.org/pdf/2210.03629>
27. What is a ReAct Agent? | IBM, fecha de acceso: julio 6, 2025, <https://www.ibm.com/think/topics/react-agent>
28. ReAct: Synergizing Reasoning and Acting in Language Models - ResearchGate, fecha de acceso: julio 6, 2025, <https://www.researchgate.net/publication/364290390_ReAct_Synergizing_Reasoning_and_Acting_in_Language_Models>
29. ReAct: Synergizing Reasoning and Acting in Language Models, fecha de acceso: julio 6, 2025, <https://react-lm.github.io/>
30. ReAct Agent: Guide to understand its functionalities and create it from scratch, fecha de acceso: julio 6, 2025, <https://www.plainconcepts.com/react-agent-ai/>
31. Building ReAct Agents from Scratch: A Hands-On Guide using Gemini - Medium, fecha de acceso: julio 6, 2025, <https://medium.com/google-cloud/building-react-agents-from-scratch-a-hands-on-guide-using-gemini-ffe4621d90ae>
32. ReAct: Synergizing Reasoning and Acting in Language Models - Hugging Face, fecha de acceso: julio 6, 2025, <https://huggingface.co/papers/2210.03629>
33. Revisiting Chain-of-Thought in Code Generation: Do Language Models Need to Learn Reasoning before Coding? | OpenReview, fecha de acceso: julio 6, 2025, [https://openreview.net/forum?id=wSZeQoJ1Vk&referrer=%5Bthe%20profile%20of%20Ren-Biao%20Liu%5D(%2Fprofile%3Fid%3D~Ren-Biao_Liu1)](https://openreview.net/forum?id=wSZeQoJ1Vk&referrer=%5Bthe+profile+of+Ren-Biao+Liu%5D%28/profile?id%3D~Ren-Biao_Liu1%29)
34. Master Tree-of-Thoughts Prompting for Better Problem-Solving - Relevance AI, fecha de acceso: julio 6, 2025, <https://relevanceai.com/prompt-engineering/master-tree-of-thoughts-prompting-for-better-problem-solving>
35. Tree of Thoughts: A New Way to Prompt AI - DEV Community, fecha de acceso: julio 6, 2025, <https://dev.to/zokizuan/tree-of-thoughts-a-new-way-to-prompt-ai-2dle>
36. Implementing ReAct Agentic Pattern From Scratch - Daily Dose of Data Science, fecha de acceso: julio 6, 2025, <https://www.dailydoseofds.com/ai-agents-crash-course-part-10-with-implementation/>
37. Unveiling Inefficiencies in LLM-Generated Code: Toward a Comprehensive Taxonomy, fecha de acceso: julio 6, 2025, <https://arxiv.org/html/2503.06327v2>
38. Code Generation with LLMs: Practical Challenges, Gotchas, and Nuances - Medium, fecha de acceso: julio 6, 2025, <https://medium.com/@adnanmasood/code-generation-with-llms-practical-challenges-gotchas-and-nuances-7b51d394f588>
39. The Hidden Risks of LLM-Generated Web Application Code : r/PromptEngineering - Reddit, fecha de acceso: julio 6, 2025, <https://www.reddit.com/r/PromptEngineering/comments/1kb5xmj/the_hidden_risks_of_llmgenerated_web_application/>
40. Multi-agent System Design Patterns From Scratch In Python | ReAct Agents - Medium, fecha de acceso: julio 6, 2025, <https://medium.com/aimonks/multi-agent-system-design-patterns-from-scratch-in-python-react-agents-e4480d099f38>
41. How to Build a ReAct Agent from Scratch with Python - YouTube, fecha de acceso: julio 6, 2025, <https://www.youtube.com/watch?v=GSep4L4vS08>
42. Let Claude think (chain of thought prompting) to increase ..., fecha de acceso: julio 6, 2025, <https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/chain-of-thought>
43. Build an Agent | ü¶úÔ∏è LangChain, fecha de acceso: julio 6, 2025, <https://python.langchain.com/docs/tutorials/agents/>
44. Agent & Tools ‚Äî Basic Code using LangChain | by Shravan Kumar - Medium, fecha de acceso: julio 6, 2025, <https://medium.com/@shravankoninti/agent-tools-basic-code-using-langchain-50e13eb07d92>
45. Building a simple Agent with Tools and Toolkits in LangChain | by Sami Maameri - Medium, fecha de acceso: julio 6, 2025, <https://medium.com/data-science/building-a-simple-agent-with-tools-and-toolkits-in-langchain-77e0f9bd1fa5>
46. "Introduction to AutoGen Studio" By Hector Perez - YouTube, fecha de acceso: julio 6, 2025, <https://www.youtube.com/watch?v=GE4RPAhiWq4>
47. Multi AI Agent Workflow‚ÄîThe End Is Nigh For Devs | by Reflections & Ideas - Desmond Loh, fecha de acceso: julio 6, 2025, <https://medium.com/@desmond2112/multi-ai-agent-workflow-the-end-is-nigh-for-devs-a12561296546>
48. Challenges to Using Large Language Models in Code Generation and Repair, fecha de acceso: julio 6, 2025, <https://www.computer.org/csdl/magazine/sp/2025/02/10942512/25p32OfDUaY>
49. Ask HN: Anyone struggling to get value out of coding LLMs? - Hacker News, fecha de acceso: julio 6, 2025, <https://news.ycombinator.com/item?id=44095189>
50. Hallucinations in code are the least dangerous form of LLM mistakes - Hacker News, fecha de acceso: julio 6, 2025, <https://news.ycombinator.com/item?id=43233903>
51. Building Autonomous AI Agents with LangGraph | Coursera, fecha de acceso: julio 6, 2025, <https://www.coursera.org/learn/packt-building-autonomous-ai-agents-with-langgraph-oyjym>
52. This is Hands Down the BEST Way to Build AI Agents - YouTube, fecha de acceso: julio 6, 2025, <https://www.youtube.com/watch?v=U6LbW2IFUQw>
53. Autonomous AI Agent: A Primer's Guide - Ozkary - Emerging Technologies, fecha de acceso: julio 6, 2025, <https://www.ozkary.com/2025/06/autonomous-ai-agent-primers-guide.html>
54. My guide on what tools to use to build AI agents (if you are a newb) - Reddit, fecha de acceso: julio 6, 2025, <https://www.reddit.com/r/AI_Agents/comments/1il8b1i/my_guide_on_what_tools_to_use_to_build_ai_agents/>